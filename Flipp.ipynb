{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to reorder the stack for user's recommendations we first need to think of a metric that reflects each users interest in a particular item. In this case I will assume items to be individual flyers. This metric which I will denote as \"degree of interest\"(DOI) will be calculated based upon the various interactions a particular user has done in the past on the Flipp App. For this assignment I will base the calculation of this score mainly on a set of explicit and implicit factors. Explicit factors will be features that affect the DOI score directly whereas implicit will affect indirectly:\n",
    "\n",
    "\n",
    "1. **Topic/Brand of Flyer read_by_user**(Explicit)- This will be a string field for the brand/store's name E.g \"Home Depot\"\n",
    "2. **Views** (Implicit)- A string field describing a particular product whose item details were viewed e.g \"GLACIER BAY VANITY 24 inch Marble top\"\n",
    "3. **Clips** (Implicit)- A boolean field specifying whether an item was clipped\n",
    "4. **Potential Saving** (Explicit)- An integer field specifying the percentage of saving made by the user if a particular view is purchased. e.g \"20%\"\n",
    "5. **Proximity** (Explicit)- Distance to the closest store from the users location related to flyer read. e.g \"5 km\" for Home depot will mean closest Home Depot store to the user was 5 km. \n",
    "6. **Category** (Explicit) - The classification of a product e.g \"Furniture\" for \"2 person couch\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These 5 factors will together contribute towards the general degree of interest score. Since the event stream being received will contain the user's id, we will generate a user profile for each individual user in the form of a table. I have generated some sample abstract raw logs describing our events stream based on two users: **Alice(id: 1)** and **Bob(id: 2)**. The logs will be annotated with column names in order to better explain the scenario. We are going to study the frequency and recurrence of the events generated by the users in order to calculate their degree of interest. For simplicity lets assume Flipp maintains a master list of type of product categories for each type of flyer. Based on the below event stream lets say following four are all the global categories:\n",
    "\n",
    "1. Furniture\n",
    "2. Home Electronics\n",
    "3. Entertainment Accessories\n",
    "4. Food and cutlery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event Logs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "| id |            flyer_read          |  product_views |category|clipped?|potential_saving %|proximity(km)|            |    |                                |                |        |        |                  |             |\n",
    "|----|--------------------------------|----------------|--------|-------|-------------------|-------------|\n",
    "|  1 |Home Depot-Update and save event|Porcelain Tiles |1       | False | 8                 |   10        |\n",
    "|----|--------------------------------|----------------|--------|-------|-------------------|-------------|\n",
    "|  1 |Walmart-New Lower Prices        |GV Frozen Pizza |4       | True  | 10                |   4         |\n",
    "|----|--------------------------------|----------------|--------|-------|-------------------|-------------|\n",
    "|  2 |Best Buy-Save on Screens        |LG 55' LED TV   |3       | True  | 20                |   25        |\n",
    "|----|--------------------------------|----------------|--------|-------|-------------------|-------------|\n",
    "|  2 |Best Buy-Black Friday blowout   |JBL Speakers    |2       | True  | 20                |   25        |\n",
    "|----|--------------------------------|----------------|--------|-------|-------------------|-------------|\n",
    "|  1 |Leons-Save the tax              |5-pc dinner set |4       | False | 30                |   8         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A clip event comprises of itself and a view event (Item cannot be clipped without viewing)\n",
    "2. A view event can happen independently\n",
    "3. Category mapping is done on core service back end which eventually lands on raw log files.\n",
    "4. Saving offers on flyers and proximity measures for users are already available in raw log files.\n",
    "5. Clip events will hold higher weightage in terms of effect on overall DOI.\n",
    "6. Flipp has a static priroty order of flyer stack for each customer i.e it has measures such as location of a user and shows all flyers in a 5-mile to 20-mile radius based on zip code or GPS.\n",
    "7. All four explicit columns have equal importance unless differentiated by a view or clip event.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#The Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case Event : View-Only**  \n",
    "- In order to determine overall interest we will install frequency counters for each of the 4 explicit columns. \n",
    "- These frequency counters will help us gauge the weightage of a particular entry both within a column and also across all columns.\n",
    "- For a particular column all the possible terms for a particular user will be extracted in a dictionary type data structure with their frequency e.g for column `category` in case of Alice:  \n",
    "  - {furniture:1, home_electronics:0, ent_accessories:0, food_cutlery:2}. \n",
    "- The normalized score for each category would be calculated by taking the weighted average i.e for furniture -> 1/3 = 0.33, food_cutlery = 0.66\n",
    "- The corrresponding score would be assigned to that particular item in a column\n",
    "- Finally a total score would be calculated based on the descriptions of the flyers in the flipp stack  \n",
    "\n",
    "**Case : Clip Event**\n",
    "- All steps would be same as above except that a +3(or any suitable value) would be added to the view-only frequency to give higher weightage \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Use Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets explain a particular use case to better understand this. Lets assume that based on Alice's past browsing pattern  we have generated the following frequency **scoring mechanism** for **Alice**:\n",
    "\n",
    "Flyer Category:\n",
    "\n",
    "1. Furniture                  0.16 (Freq:1, 1/6)\n",
    "2. Home Electronics           0.00\n",
    "3. Entertainment Accessories  0.00\n",
    "4. Food and cutlery           0.84 (Freq: 4+1=5, 5/6) --(Walmart event was a clip because of which 1+3=4)\n",
    "\n",
    "Potential Saving:\n",
    "1. less than 10%               0.16 (1/6) \n",
    "2. 10`-`20%                    0.66  ((1+(3))/6)\n",
    "3. greater than 20%            0.16  (1/6)\n",
    "\n",
    "Proximity:\n",
    "1. less than 5km              0.66 (4/6)\n",
    "2. 5`-`10                     0.33 (2/6)\n",
    "3. greater than 10km          0.00\n",
    " \n",
    "Brand Preference:    \n",
    "1. Home Depot                 0.16  \n",
    "2. Walmart                    0.66  \n",
    "3. Leon's                     0.16  \n",
    "4. BestBuy                    0.00  \n",
    "\n",
    "\n",
    "Now lets assume that flipp has numerous flyers in its stack ,in context of Alice,which need to be reordered. Following is the **static** order of a particular stack:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Flipp Stack ( Static)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Stack_order,Flyer_name,Category_ids,Saving_offer,Proximity  \n",
    "1          ,HomeDepot ,         [4],          40,    11  \n",
    "2          ,BestBuy   ,         [3],          20,    5  \n",
    "3          ,IKEA      ,       [1,4],          15,    8  \n",
    "4          ,Walmart   ,   [1,2,3,4],          30,    5  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###The DOI calculation for Alice"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Based on the above 4 flyers the respective degree of interest scores calculated using the scoring mechanism for Alice would be:\n",
    "\n",
    "Stack_order,Brand Score, Category Score,Saving Score,Proximity Score,Degree_of_Interest  \n",
    "1             0.16    +         0.84  +     0.16   +   0.00        =      1.16   \n",
    "2             0.00    +         0.00  +     0.66   +   0.33        =      1.00  \n",
    "3             0.00    +         1.00  +     0.66   +   0.33        =      2.00  \n",
    "4             0.66    +         1.00  +     0.16   +   0.33        =      2.15  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Case Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Even though _IKEA_ is a brand that was new to Alice's history, still based on the DOI calculated above it would take second precedence in the overall stack due to Alice's viewing patterns. \n",
    "2. The rough ranges generated for this example are for simplicity. This is just to illustrate the concept of scoring otherwise finding optimum number of ranges and their respective lengths is a separate topic that would require considerable insight. \n",
    "\n",
    "__Based on the Degree of Interest Scores the new stack ordering for Alice would be 4,3,1,2. Therefore now whenever Alice opens the Flipp App, the updated DOI scores would be fetched for the available stack of flyers and as a result she would see flyers from Walmart on the top,followed by IKEA,Home Depot and BestBuy . Even though this data is insufficient to make any conclusions about Alice's choices, if given access to the right amounts of data, these frequency ratios would self normalize themselves near their true values.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorted Stack"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Stack_order,Flyer_name,\n",
    "4           Walmart \n",
    "3           IKEA   \n",
    "1           HomeDepot\n",
    "2           BestBuy   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
